
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Batch Learning from Bandit Feedback &#8212; ope-rec</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/quantecon-book-theme.857ff391aaabaeb8c161d2309c375fe6.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="_static/quantecon-book-theme.76bf49d7bbc59738cdb03766fad654af.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Evaluating the Robustness of Off-Policy Evaluation" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html" />
    <link rel="prev" title="Off-Policy Learning in Two-stage Recommender Systems" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Sparsh A." />
<meta name="keywords" content="" />
<meta name="description" content=Batch Learning from Bandit Feedback  Imports  import math import pandas as pd import numpy as np import warnings import seaborn as sns import matplotlib.pyplot  />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Batch Learning from Bandit Feedback"/>
<meta name="twitter:description" content="Batch Learning from Bandit Feedback  Imports  import math import pandas as pd import numpy as np import warnings import seaborn as sns import matplotlib.pyplot ">
<meta name="twitter:creator" content="@">
<meta name="twitter:image" content="">

<!-- Opengraph tags -->
<meta property="og:title" content="Batch Learning from Bandit Feedback" />
<meta property="og:type" content="website" />
<meta property="og:url" content="None" />
<meta property="og:image" content="" />
<meta property="og:description" content="Batch Learning from Bandit Feedback  Imports  import math import pandas as pd import numpy as np import warnings import seaborn as sns import matplotlib.pyplot " />
<meta property="og:site_name" content="ope-rec" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="wrapper">

        <div class="main">

            <div class="page" id=T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)>

                <div class="page__toc">

                    <div class="inner">

                        
                        <div class="page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utils">
   Utils
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-to-bandit-transform-stbt">
   Supervised to Bandit Transform (STBT)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#off-policy-evaluation-estimators">
   Off-Policy Evaluation Estimators
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-datasets-used-in-experiments">
   Sample datasets used in experiments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-the-following-methods">
   Compare the following methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#off-policy-learning-estimators">
   Off-Policy Learning Estimators
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-using-doubly-robust-as-opposed-to-the-ips-estimator">
   Alternative using Doubly Robust (as opposed to the IPS estimator)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-data">
   Read data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#perform-supervised-to-bandit-conversion">
   Perform Supervised-to-Bandit Conversion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#skyline">
   Skyline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#counterfactual-risk-minimization-crm">
   Counterfactual Risk Minimization (CRM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experiments">
   Experiments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                            <p class="logo">
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="page__header">

                    <div class="page__header-copy">

                        <p class="page__header-heading"><a href="US773842_Off_Policy_Evaluation.html">ope-rec</a></p>

                        <p class="page__header-subheading">Batch Learning from Bandit Feedback</p>

                    </div>

                    <p class="page__header-authors">Sparsh A.</p>

                </div> <!-- .page__header -->



                
                <main class="page__content" role="main">
                    
                    <div>
                        
  <div class="tex2jax_ignore mathjax_ignore section" id="batch-learning-from-bandit-feedback">
<h1>Batch Learning from Bandit Feedback<a class="headerlink" href="#batch-learning-from-bandit-feedback" title="Permalink to this headline">¶</a></h1>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">sklearn.model_selection</span>
<span class="kn">import</span> <span class="nn">sklearn.preprocessing</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> 

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble.forest</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span><span class="p">,</span> <span class="n">load_breast_cancer</span><span class="p">,</span> <span class="n">load_wine</span><span class="p">,</span> <span class="n">fetch_openml</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="utils">
<h2>Utils<a class="headerlink" href="#utils" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_interactions</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">T</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">one_hot_labeler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">one_hot_labeler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">one_hot_labeler</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">XT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">XT</span><span class="p">[:,</span><span class="n">cnt</span><span class="p">]</span><span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">T</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">XT</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">X_full</span><span class="p">,</span> <span class="n">lb_fit</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="supervised-to-bandit-transform-stbt">
<h2>Supervised to Bandit Transform (STBT)<a class="headerlink" href="#supervised-to-bandit-transform-stbt" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">STBT</span><span class="p">:</span>
   
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs Supervised to Bandit Conversion for classification </span>
<span class="sd">    datasets. This conversion is generally used to test the limits of </span>
<span class="sd">    counterfactual learning in a well-controlled environment [1,2,3]. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    train_frac : float, default: 0.50</span>
<span class="sd">        It should be between 0.0 and 1.0 and represents the</span>
<span class="sd">        proportion of the dataset to include in the train split.</span>
<span class="sd">        </span>
<span class="sd">    permute : bool, default: False</span>
<span class="sd">        Randomly permute the data before the random split between train and test.</span>
<span class="sd">    logging_type : str, default: &quot;uniform&quot;</span>
<span class="sd">        The type of logging policy. If &quot;uniform&quot;, uniform random samples from the </span>
<span class="sd">        labels $y$ to simulate a logging policy. If &quot;biased&quot;, the logging policy</span>
<span class="sd">        is a stochastic function of the covariates.</span>
<span class="sd">        </span>
<span class="sd">    sample_frac : float, default: None</span>
<span class="sd">        A sample fraction between (0.0,1.0]. This is the sample fraction of the</span>
<span class="sd">        training data used to fit the target policy. By default, the full</span>
<span class="sd">        training set is used. </span>
<span class="sd">     </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, </span>
<span class="sd">           Proceedings of Machine Learning Research, 48, 652--661, 2016.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">           1731--1755, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">           </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)  </span>
<span class="sd">    &gt;&gt;&gt; obj = STBT()</span>
<span class="sd">    &gt;&gt;&gt; sample_batch = obj.generate_batch(X, y)</span>
<span class="sd">    &gt;&gt;&gt; sample_batch.y_train_logging[0:5]</span>
<span class="sd">    array([1, 1, 0, 0, 0]))</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.50</span><span class="p">,</span> <span class="n">permute</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">logging_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">,</span>
                 <span class="n">sample_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="n">train_frac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">permute</span> <span class="o">=</span> <span class="n">permute</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="o">=</span> <span class="n">logging_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">=</span> <span class="n">sample_frac</span>
        
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_validate_input</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`train_frac` should be a float in (0.0,1.0), got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`sample_frac` should be a float in (0.0,1.0], got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;biased&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`logging_type` should be either &#39;uniform&#39; or &#39;biased&#39;, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        
        <span class="n">kw</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xrel</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="n">exp_xrel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">xrel</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">exp_xrel</span> <span class="o">/</span> <span class="n">exp_xrel</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>  
         
        <span class="k">return</span> <span class="n">p</span>
        
         
    <span class="k">def</span> <span class="nf">generate_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate Supervised to Bandit batch</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array of shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>
<span class="sd">        y : array of shape (n_samples,)</span>
<span class="sd">            Target vector relative to X.</span>
<span class="sd">        **kwargs : Arguments passed to fit method in </span>
<span class="sd">                   `sklearn.linear_model.LogisticRegression` class.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_train : array of shape (n_train_samples, n_features)</span>
<span class="sd">        y_train : array of shape (n_train_samples,)</span>
<span class="sd">        X_test : array of shape (n_test_samples, n_features)</span>
<span class="sd">        y_test : array of shape (n_test_samples,)</span>
<span class="sd">        y_train_logging : array of shape (n_train_samples,)</span>
<span class="sd">            Logging policy labels on train data</span>
<span class="sd">        train_logging_probs : array of shape (n_train_samples, n_classes)     </span>
<span class="sd">            Logging policy probabilities on train data</span>
<span class="sd">        train_logging_prob : array of shape (n_train_samples,)</span>
<span class="sd">            Logging policy probability corresponding to the chosen logging label on train data</span>
<span class="sd">        y_train_logging_idx : array of shape (n_train_samples, n_classes)</span>
<span class="sd">            Binary matrix with 1s indicating which action was taken by the logging policy in train data</span>
<span class="sd">           </span>
<span class="sd">        y_test_logging : array of shape (n_test_samples,)</span>
<span class="sd">             Logging policy labels on test data</span>
<span class="sd">        test_logging_probs : array of shape (n_test_samples, n_classes)   </span>
<span class="sd">            Logging policy probabilities on test data</span>
<span class="sd">        test_logging_prob : array of shape (n_test_samples,)</span>
<span class="sd">            Logging policy probability corresponding to the chosen logging label on test data</span>
<span class="sd">       </span>
<span class="sd">        y_train_target : array of shape (n_train_samples,)</span>
<span class="sd">             Target policy labels on train data</span>
<span class="sd">        train_target_prob : array of shape (n_train_samples, n_classes)     </span>
<span class="sd">             Target policy probabilities on train data</span>
<span class="sd">        train_target_probs : array of shape (n_train_samples,)</span>
<span class="sd">            Target policy probability corresponding to the chosen logging label on train data</span>
<span class="sd">       </span>
<span class="sd">        y_test_target : array of shape (n_test_samples,)</span>
<span class="sd">             Target policy labels on test data</span>
<span class="sd">        test_target_prob : array of shape (n_test_samples, n_classes)     </span>
<span class="sd">             Target policy probabilities on test data</span>
<span class="sd">        test_target_probs : array of shape (n_test_samples,)</span>
<span class="sd">            Target policy probability corresponding to the chosen logging label on test data</span>
<span class="sd">       </span>
<span class="sd">        true_target_value_test : float</span>
<span class="sd">            True value of Target policy on test data</span>
<span class="sd">       </span>
<span class="sd">        train_logging_reward : array of shape (n_train_samples,)</span>
<span class="sd">            Observed reward of logging policy on train data </span>
<span class="sd">        test_logging_reward : array of shape (n_test_samples,)</span>
<span class="sd">            Observed reward of logging policy on test data </span>
<span class="sd">            </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_input</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_batch_call</span> <span class="o">=</span> <span class="kc">True</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span>
            <span class="n">permute</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">permute</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">permute</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> \
            <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">train_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">)</span> 
            
        <span class="n">n_train_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">n_test_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    
        <span class="n">y_train_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_train_samples</span><span class="p">)</span>  
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">n_train_samples</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_test_samples</span><span class="p">)</span>  
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">n_test_samples</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span> 
        
        <span class="k">else</span><span class="p">:</span>
            
            <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)))</span>
            <span class="n">lp_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">@</span> <span class="n">W</span>
            <span class="n">lp_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">@</span> <span class="n">W</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">lp_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">lp_test</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">y_test_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_test_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
                <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span><span class="p">[</span><span class="n">sample</span><span class="p">,:],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">choice</span>
            
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">):</span>
                <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span><span class="p">[</span><span class="n">sample</span><span class="p">,:],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">y_test_logging_idx</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">choice</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_train_u</span><span class="p">,]</span><span class="o">*</span><span class="n">n_train_samples</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_train_u</span><span class="p">,]</span><span class="o">*</span><span class="n">n_test_samples</span><span class="p">)[</span><span class="n">y_test_logging_idx</span><span class="p">]</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span><span class="p">[</span><span class="n">y_test_logging_idx</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_subsamples</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">*</span> <span class="n">n_train_samples</span><span class="p">)</span>
            <span class="n">idx_subsamples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_subsamples</span><span class="p">)</span>
            <span class="n">X_train_subsamples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx_subsamples</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_train_subsamples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx_subsamples</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">n_subsamples</span> <span class="o">&lt;</span> <span class="n">n_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">=</span><span class="kc">True</span>
            <span class="n">target_policy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_subsamples</span><span class="p">,</span> <span class="n">y_train_subsamples</span><span class="p">)</span>
       
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">n_train_samples</span> <span class="o">&lt;</span> <span class="n">n_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">=</span><span class="kc">True</span>
            <span class="n">target_policy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span> <span class="o">=</span> <span class="n">target_policy</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span> <span class="o">=</span> <span class="n">target_policy</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
         
        <span class="n">y_train_target</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">train_target_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">y_test_target</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">test_target_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
         
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
            <span class="n">y_train_target_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                 <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,:])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">y_train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train_target_i</span><span class="p">)</span>
            <span class="n">train_target_prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="n">y_train_target_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train_target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_target_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_target_prob</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">):</span>
            <span class="n">y_test_target_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                 <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,:])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">y_test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_target_i</span><span class="p">)</span>
            <span class="n">test_target_prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="n">y_test_target_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_test_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_test_target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_target_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_target_prob</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">true_target_value_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_reward</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">)</span>
           
        <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="off-policy-evaluation-estimators">
<h2>Off-Policy Evaluation Estimators<a class="headerlink" href="#off-policy-evaluation-estimators" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PolicyEvaluation</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs off-policy evaluation with bandit feedback. </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        method : str, default: &#39;ips&#39;.</span>
<span class="sd">            The policy evaluation method. The default is &#39;ips&#39;.</span>
<span class="sd">            It should be one of: &#39;ips&#39; (Inverse Propensity Score), </span>
<span class="sd">            &#39;dm&#39; (Direct Method), &#39;dr&#39; (Doubly Robust), &#39;switch&#39;</span>
<span class="sd">            (SWITCH estimator).</span>
<span class="sd">            </span>
<span class="sd">        tau : float, default: 0.001.</span>
<span class="sd">            Hyperparameter added to IPS or SWICTH estimator for numerical stability. </span>
<span class="sd">            </span>
<span class="sd">            For method=&#39;ips&#39;, the logging probabilities in the test set get adjusted by</span>
<span class="sd">            the max(logging probabilities, tau).</span>
<span class="sd">            </span>
<span class="sd">            For method = &#39;switch&#39;, when logging probabilities are larger than this parameter,</span>
<span class="sd">            the &#39;dm&#39; estimator is applied, otherwise the &#39;dr&#39; estimator is applied. </span>
<span class="sd">            </span>
<span class="sd">            </span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">    </span>
<span class="sd">        .. [1] Y. Wang, A. Agarwal and M. Dud\&#39;{\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, </span>
<span class="sd">               Proceedings of Machine Learning Research, 70, 3589--3597, 2017.</span>
<span class="sd">        .. [2] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, </span>
<span class="sd">               Proceedings of Machine Learning Research, 48, 652--661, 2016.</span>
<span class="sd">        .. [3] K{\&quot;u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous </span>
<span class="sd">               treatment effects using machine learning, Proceedings of the National Academy of Sciences, </span>
<span class="sd">               116(10), 4156--4165, 2019. </span>
<span class="sd">               </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">        &gt;&gt;&gt; from blbf.STBT import STBT</span>
<span class="sd">        &gt;&gt;&gt; from blbf.PolicyEvaluation import PolicyEvaluation </span>
<span class="sd">        &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)</span>
<span class="sd">        &gt;&gt;&gt; obj = STBT(train_frac= 0.5)</span>
<span class="sd">        &gt;&gt;&gt; data = obj.generate_batch(X, y, max_iter=1000)</span>
<span class="sd">        &gt;&gt;&gt; PolicyEvaluation(method=&#39;dr&#39;).evaluate_policy(data = data)</span>
<span class="sd">        0.7241601514218099</span>
<span class="sd">        &quot;&quot;&quot;</span>
    
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;ips&#39;</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span> 
            
            <span class="n">valid_methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">,</span> <span class="s1">&#39;dm&#39;</span><span class="p">,</span> <span class="s1">&#39;dr&#39;</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_methods</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not a valid method.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
        
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`tau` must be in the (0, 1) interval, got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span>
                       
        <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            
            <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
            <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
        
        <span class="k">def</span> <span class="nf">evaluate_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            data : STBT object</span>
<span class="sd">                This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">                `generate_batch` method.</span>
<span class="sd">                </span>
<span class="sd">            clf : str, default: &#39;LogisticRegression&#39;</span>
<span class="sd">            A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">            &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">           </span>
<span class="sd">            **kwargs : Arguments passed to clf.</span>
<span class="sd">    </span>
<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            float.</span>
<span class="sd">              The estimated value of the policy.</span>
<span class="sd">        </span>
<span class="sd">            &quot;&quot;&quot;</span>
              
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;generate_batch_call&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The method `generate_batch` must be called first on the instance: </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data</span><span class="p">))</span>
                                    
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ips&#39;</span><span class="p">:</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">adj_test_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span><span class="p">)</span>  
                
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">adj_test_logging_prob</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span>
                
                <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">*</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">)</span> <span class="o">/</span> <span class="n">adj_test_logging_prob</span><span class="p">)</span>
                
            <span class="k">else</span><span class="p">:</span>
                <span class="n">XY_train</span><span class="p">,</span> <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
                <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XY_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span>
                <span class="n">XY_test_target</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">,</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
                <span class="n">test_target_pred_reward</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_target</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">]:</span>
                    <span class="n">XY_test_logging</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">,</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
                    <span class="n">test_logging_pred_reward</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_logging</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">dr_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">-</span> <span class="n">test_logging_pred_reward</span><span class="p">)</span> <span class="o">*</span> \
                                 <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">)</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dm&#39;</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_target_pred_reward</span><span class="p">)</span> 
                    
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dr&#39;</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_target_pred_reward</span> <span class="o">+</span> <span class="n">dr_adj</span><span class="p">)</span>
                        
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;switch&#39;</span><span class="p">:</span>
                    <span class="n">switch_indicator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                    <span class="n">switch_estimator_rewards</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">switch_indicator</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">dr_adj</span> <span class="o">+</span> <span class="n">test_target_pred_reward</span><span class="p">)</span>
                    <span class="n">switch_estimator_rewards</span> <span class="o">+=</span> <span class="n">switch_indicator</span> <span class="o">*</span> <span class="n">test_target_pred_reward</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">switch_estimator_rewards</span><span class="p">)</span>
          
            <span class="k">return</span> <span class="n">v</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-datasets-used-in-experiments">
<h2>Sample datasets used in experiments<a class="headerlink" href="#sample-datasets-used-in-experiments" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Get data (features and labels) used in experiments.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    dataset : str, default: None </span>
<span class="sd">        It should be one of: &#39;ecoli&#39;, &#39;glass&#39;, &#39;letter-recognition&#39;, </span>
<span class="sd">        &#39;lymphography&#39;, &#39;yeast&#39;, &#39;digits&#39;, &#39;breast-cancer&#39;, &#39;wine&#39;, or </span>
<span class="sd">        &#39;mnist&#39;.</span>
<span class="sd">        </span>
<span class="sd">    scale : bool, default: True</span>
<span class="sd">        Standardize features by zero mean and unit variance.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    </span>
<span class="sd">    tuple, length=2 </span>
<span class="sd">        tuple containing features-target split of inputs.</span>
<span class="sd">        </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. </span>
<span class="sd">    Irvine, CA: University of California, School of Information and Computer Science.</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)</span>
<span class="sd">    &gt;&gt;&gt; X[0,:]</span>
<span class="sd">    array([0.49, 0.29, 0.48, 0.5 , 0.56, 0.24, 0.35])</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">,</span> <span class="s1">&#39;mnist&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid dataset provided.&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">]:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/&#39;</span> 
        <span class="n">f</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s2">&quot;.data&quot;</span>
     
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span>  <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">]:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">]:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;digits&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;wine&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
        
    <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;ecoli&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;glass&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">]:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span><span class="o">.</span><span class="n">values</span>
     
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;yeast&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;mnist&#39;</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">)</span> 

    <span class="k">if</span> <span class="n">scale</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="compare-the-following-methods">
<h2>Compare the following methods<a class="headerlink" href="#compare-the-following-methods" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>IPS: Inverse Propensity Score</p></li>
<li><p>DM: Direct Method (Reward Prediction)</p></li>
<li><p>DR: Doubly Robust</p></li>
<li><p>SWITCH: Switch Estimator</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ComparePolicyEvaluation</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">datasets</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">B</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">fit_policies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> 
                        <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">]</span> <span class="c1"># &#39;letter-recognition&#39;</span>
        <span class="n">dat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">true_value</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">ips</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">dm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">dr</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">switch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample: </span><span class="si">%d</span><span class="s2"> - Dataset: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
                <span class="n">d</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">()</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
                <span class="n">dat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                <span class="n">true_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">true_target_value_test</span><span class="p">)</span>
                <span class="n">ips</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;ips&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">))</span>
                <span class="n">dm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;dm&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                <span class="n">dr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;dr&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                <span class="n">switch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;switch&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
           
        <span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;dataset&#39;</span><span class="p">:</span><span class="n">dat</span><span class="p">,</span> <span class="s1">&#39;true_value&#39;</span><span class="p">:</span><span class="n">true_value</span><span class="p">,</span> <span class="s1">&#39;ips&#39;</span><span class="p">:</span><span class="n">ips</span><span class="p">,</span>
                                     <span class="s1">&#39;dm&#39;</span><span class="p">:</span> <span class="n">dm</span><span class="p">,</span> <span class="s1">&#39;dr&#39;</span><span class="p">:</span><span class="n">dr</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">:</span> <span class="n">switch</span><span class="p">})</span>
    
        <span class="c1"># Bias</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
        <span class="c1"># Relative risk</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">res</span> <span class="o">=</span> <span class="n">res</span>
       
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">get_summary_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">res_summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">res</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span>
                            <span class="s1">&#39;ips_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;dm_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;dr_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;switch_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;ips_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;dm_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;dr_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;switch_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
                            <span class="p">})</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">res_summary</span> <span class="o">=</span> <span class="n">res_summary</span>
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">plot_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">res_long</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">res</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">var_name</span> <span class="o">=</span> <span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">value_name</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span>
                  <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ips_bias&#39;</span><span class="p">,</span>  <span class="s1">&#39;dm_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;dr_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;switch_bias&#39;</span><span class="p">])</span>

        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;method&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;box&quot;</span><span class="p">,</span> 
                          <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">res_long</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="p">)):</span>
            <span class="n">ax_i</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">ax_i</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span> <span class="o">=</span> <span class="n">ComparePolicyEvaluation</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit_policies</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: ecoli
Sample: 10 - Dataset: ecoli
Sample: 20 - Dataset: ecoli
Sample: 30 - Dataset: ecoli
Sample: 40 - Dataset: ecoli
Sample: 50 - Dataset: ecoli
Sample: 60 - Dataset: ecoli
Sample: 70 - Dataset: ecoli
Sample: 80 - Dataset: ecoli
Sample: 90 - Dataset: ecoli
Sample: 0 - Dataset: glass
Sample: 10 - Dataset: glass
Sample: 20 - Dataset: glass
Sample: 30 - Dataset: glass
Sample: 40 - Dataset: glass
Sample: 50 - Dataset: glass
Sample: 60 - Dataset: glass
Sample: 70 - Dataset: glass
Sample: 80 - Dataset: glass
Sample: 90 - Dataset: glass
Sample: 0 - Dataset: lymphography
Sample: 10 - Dataset: lymphography
Sample: 20 - Dataset: lymphography
Sample: 30 - Dataset: lymphography
Sample: 40 - Dataset: lymphography
Sample: 50 - Dataset: lymphography
Sample: 60 - Dataset: lymphography
Sample: 70 - Dataset: lymphography
Sample: 80 - Dataset: lymphography
Sample: 90 - Dataset: lymphography
Sample: 0 - Dataset: yeast
Sample: 10 - Dataset: yeast
Sample: 20 - Dataset: yeast
Sample: 30 - Dataset: yeast
Sample: 40 - Dataset: yeast
Sample: 50 - Dataset: yeast
Sample: 60 - Dataset: yeast
Sample: 70 - Dataset: yeast
Sample: 80 - Dataset: yeast
Sample: 90 - Dataset: yeast
Sample: 0 - Dataset: digits
Sample: 10 - Dataset: digits
Sample: 20 - Dataset: digits
Sample: 30 - Dataset: digits
Sample: 40 - Dataset: digits
Sample: 50 - Dataset: digits
Sample: 60 - Dataset: digits
Sample: 70 - Dataset: digits
Sample: 80 - Dataset: digits
Sample: 90 - Dataset: digits
Sample: 0 - Dataset: breast-cancer
Sample: 10 - Dataset: breast-cancer
Sample: 20 - Dataset: breast-cancer
Sample: 30 - Dataset: breast-cancer
Sample: 40 - Dataset: breast-cancer
Sample: 50 - Dataset: breast-cancer
Sample: 60 - Dataset: breast-cancer
Sample: 70 - Dataset: breast-cancer
Sample: 80 - Dataset: breast-cancer
Sample: 90 - Dataset: breast-cancer
Sample: 0 - Dataset: wine
Sample: 10 - Dataset: wine
Sample: 20 - Dataset: wine
Sample: 30 - Dataset: wine
Sample: 40 - Dataset: wine
Sample: 50 - Dataset: wine
Sample: 60 - Dataset: wine
Sample: 70 - Dataset: wine
Sample: 80 - Dataset: wine
Sample: 90 - Dataset: wine
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span><span class="o">.</span><span class="n">get_summary_stats</span><span class="p">()</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">res_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>dataset</th>
      <th colspan="2" halign="left">ips_bias</th>
      <th colspan="2" halign="left">dm_bias</th>
      <th colspan="2" halign="left">dr_bias</th>
      <th colspan="2" halign="left">switch_bias</th>
      <th colspan="2" halign="left">ips_rr</th>
      <th colspan="2" halign="left">dm_rr</th>
      <th colspan="2" halign="left">dr_rr</th>
      <th colspan="2" halign="left">switch_rr</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>breast-cancer</td>
      <td>0.015439</td>
      <td>0.056258</td>
      <td>0.031097</td>
      <td>0.014548</td>
      <td>0.002050</td>
      <td>0.009696</td>
      <td>0.002050</td>
      <td>0.009696</td>
      <td>0.051048</td>
      <td>0.033579</td>
      <td>0.032639</td>
      <td>0.015079</td>
      <td>0.008363</td>
      <td>0.006185</td>
      <td>0.008363</td>
      <td>0.006185</td>
    </tr>
    <tr>
      <th>1</th>
      <td>digits</td>
      <td>-0.000356</td>
      <td>0.099657</td>
      <td>0.271003</td>
      <td>0.036489</td>
      <td>-0.003003</td>
      <td>0.045847</td>
      <td>-0.003003</td>
      <td>0.045847</td>
      <td>0.086759</td>
      <td>0.063050</td>
      <td>0.291985</td>
      <td>0.039215</td>
      <td>0.039939</td>
      <td>0.029041</td>
      <td>0.039939</td>
      <td>0.029041</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ecoli</td>
      <td>0.036131</td>
      <td>0.159114</td>
      <td>0.221680</td>
      <td>0.069068</td>
      <td>0.021395</td>
      <td>0.082412</td>
      <td>0.021395</td>
      <td>0.082412</td>
      <td>0.168851</td>
      <td>0.126703</td>
      <td>0.288876</td>
      <td>0.088675</td>
      <td>0.086244</td>
      <td>0.068031</td>
      <td>0.086244</td>
      <td>0.068031</td>
    </tr>
    <tr>
      <th>3</th>
      <td>glass</td>
      <td>-0.005234</td>
      <td>0.135409</td>
      <td>0.108039</td>
      <td>0.077705</td>
      <td>-0.015941</td>
      <td>0.102587</td>
      <td>-0.015941</td>
      <td>0.102587</td>
      <td>0.231339</td>
      <td>0.168950</td>
      <td>0.231582</td>
      <td>0.136500</td>
      <td>0.177798</td>
      <td>0.135564</td>
      <td>0.177798</td>
      <td>0.135564</td>
    </tr>
    <tr>
      <th>4</th>
      <td>lymphography</td>
      <td>-0.030135</td>
      <td>0.166516</td>
      <td>0.210184</td>
      <td>0.112056</td>
      <td>-0.006171</td>
      <td>0.097335</td>
      <td>-0.006171</td>
      <td>0.097335</td>
      <td>0.166880</td>
      <td>0.141465</td>
      <td>0.278812</td>
      <td>0.132798</td>
      <td>0.100086</td>
      <td>0.078494</td>
      <td>0.100086</td>
      <td>0.078494</td>
    </tr>
    <tr>
      <th>5</th>
      <td>wine</td>
      <td>0.004831</td>
      <td>0.121543</td>
      <td>0.123857</td>
      <td>0.042780</td>
      <td>-0.000622</td>
      <td>0.038650</td>
      <td>-0.000622</td>
      <td>0.038650</td>
      <td>0.099961</td>
      <td>0.082773</td>
      <td>0.132158</td>
      <td>0.045198</td>
      <td>0.031962</td>
      <td>0.026401</td>
      <td>0.031962</td>
      <td>0.026401</td>
    </tr>
    <tr>
      <th>6</th>
      <td>yeast</td>
      <td>-0.010755</td>
      <td>0.071710</td>
      <td>0.080556</td>
      <td>0.037969</td>
      <td>-0.006330</td>
      <td>0.058608</td>
      <td>-0.006330</td>
      <td>0.058608</td>
      <td>0.127633</td>
      <td>0.097028</td>
      <td>0.178583</td>
      <td>0.078501</td>
      <td>0.105852</td>
      <td>0.077361</td>
      <td>0.105852</td>
      <td>0.077361</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span><span class="o">.</span><span class="n">plot_bias</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)_15_0.png" src="_images/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)_15_0.png" />
</div>
</div>
</div>
<div class="section" id="off-policy-learning-estimators">
<h2>Off-Policy Learning Estimators<a class="headerlink" href="#off-policy-learning-estimators" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EvaluationMetrics</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">error_rate</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">er</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">er</span>

<span class="k">class</span> <span class="nc">BanditDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_idx</span> <span class="o">=</span> <span class="n">y_idx</span>
        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_idx</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="fm">__len__</span> <span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
    
    
<span class="k">class</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">xw_plus_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xw_plus_b</span> <span class="c1"># batch size x n_actions</span>
    
<span class="k">class</span> <span class="nc">NonLinearModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span><span class="n">n_actions</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
   

<span class="k">class</span> <span class="nc">RewardPredictor</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using by directly predicting the Reward as a function of covariates, </span>
<span class="sd">    actions and their interaction. </span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">           1731--1755, 2015.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="sd">           International Conference on Learning Representations,  2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
        
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        clf : str, default: &#39;LogisticRegression&#39;</span>
<span class="sd">        A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">        &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">       </span>
<span class="sd">        **kwargs : Arguments passed to clf.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>    
    
        <span class="n">XY_train</span><span class="p">,</span> <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="n">y_train_logging_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_pred_reward_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">)])</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">)])</span> 
        <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XY_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">yval</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">):</span>
           <span class="n">XY_train_yval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
           <span class="n">XY_test_yval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">train_pred_reward_arr</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_train_yval</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_yval</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
             
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
             
        <span class="k">return</span> <span class="bp">self</span>
    
<span class="k">class</span> <span class="nc">OutcomeWeightedLearning</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning by transforming the learning problem into a </span>
<span class="sd">    weighted multi-class classification problem. </span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment </span>
<span class="sd">           Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, </span>
<span class="sd">           107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.</span>
<span class="sd">    &quot;&quot;&quot;</span>
        
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;SVC&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        clf : str, default: &#39;SVC&#39;</span>
<span class="sd">        A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">        &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">       </span>
<span class="sd">        **kwargs : Arguments passed to clf.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>    
        
        <span class="n">wt</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span>
        
        <span class="k">if</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;SVC&#39;</span><span class="p">,</span> <span class="s1">&#39;RandomForestClassifier&#39;</span><span class="p">]:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">wt</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">]:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">wt</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span>
         

<span class="k">class</span> <span class="nc">VowpalWabbit</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using Vowpal Wabbit. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    method : str, default: &#39;ips&#39;</span>
<span class="sd">        The policy evaluation approach to optimize a policy. Vowpal Wabbit offers four </span>
<span class="sd">        approaches to specify a contextual bandit approach:</span>
<span class="sd">            * Inverse Propensity Score: &#39;ips&#39;</span>
<span class="sd">            * Doubly Robust: &#39;dr&#39;</span>
<span class="sd">            * Direct Method: &#39;dm&#39;</span>
<span class="sd">            * Multi Task Regression/Importance Weighted Regression: &#39;mtr&#39; </span>
<span class="sd">       </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Bietti and A. Agarwal and J. Langford, A Contextual Bandit Bake-off, </span>
<span class="sd">        arXiv preprint arXiv:1802.04064, 2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;dr&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_train_vw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="s2">&quot;--cb_type&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span>  <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_actions</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># input requires cost instead of reward</span>
            <span class="n">probability</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">train_features_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">train_features_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">]))</span>
                <span class="n">train_features</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_features_ls</span><span class="p">)</span>
            <span class="n">learn_example</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; | &quot;</span> <span class="o">+</span> <span class="n">train_features</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">learn_example</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">vw</span>
    
    <span class="k">def</span> <span class="nf">_predict_vw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vw_object</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">test_features_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">test_features_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">]))</span>
                <span class="n">features</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_features_ls</span><span class="p">)</span>
            <span class="n">test_example</span> <span class="o">=</span> <span class="s2">&quot; | &quot;</span> <span class="o">+</span> <span class="n">features</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">vw_object</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_example</span><span class="p">)</span> 
            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">predictions</span> 
        
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="n">vw_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_vw</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_vw</span><span class="p">(</span><span class="n">vw_fit</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span>

<span class="k">class</span> <span class="nc">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using the Counterfactual Risk Minimization </span>
<span class="sd">    approach proposed in [1], and later refined in [2].</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    batch_size : int, default: 96</span>
<span class="sd">        The number of samples per batch to load </span>
<span class="sd">    learning_rate : float, default: 0.01</span>
<span class="sd">        Stochastic gradient descent learning rate </span>
<span class="sd">    weight_decay : float, default: 0.001</span>
<span class="sd">        L2 regularization on parameters</span>
<span class="sd">    lambda_ : float, default: 0.1</span>
<span class="sd">        Variance regularization. Penalty on the variance of the </span>
<span class="sd">        learnt policy relative to the logging policy.</span>
<span class="sd">    self_normalize: bool, default: True</span>
<span class="sd">        Whether to normalize the IPS estimator. See [2].</span>
<span class="sd">    clipping: float, default: 100.</span>
<span class="sd">        Clipping the importance sample weights. See [1].</span>
<span class="sd">    verbose: bool, default: False</span>
<span class="sd">        Whether to print Poem Loss during training .</span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">            1731--1755, 2015.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="sd">            International Conference on Learning Representations,  2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">96</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> 
                 <span class="n">lambda_</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">self_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">clipping</span> <span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span> <span class="o">=</span> <span class="n">self_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="n">clipping</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
       
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_poem_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> 
            <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
        
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">pi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">softmax_pi</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pi_i</span> <span class="o">=</span> <span class="n">softmax_pi</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">y_idx</span><span class="p">)</span>
        <span class="n">log_importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pi_i</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span><span class="p">)</span> 
        <span class="n">importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_importance</span><span class="p">)</span>    
        <span class="n">clip_importance_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">clip_importance_vals</span><span class="p">,</span> <span class="n">importance</span><span class="p">)</span>
        <span class="n">off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="c1"># Eq.(8) in [2] </span>
        <span class="n">var_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">off_policy_est</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">pi_i</span><span class="p">,</span> <span class="n">p0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">var_d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">pi_i</span><span class="p">,</span> <span class="n">p0</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">empirical_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">var_n</span><span class="p">,</span> <span class="n">var_d</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span><span class="p">:</span>
            <span class="n">effective_sample_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="c1"># turns off requires grad</span>
            <span class="n">mean_off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">off_policy_est</span><span class="p">),</span> <span class="n">effective_sample_size</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mean_off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">off_policy_est</span><span class="p">)</span>
        
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">Lambda</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">empirical_var</span><span class="p">,</span> <span class="n">bsz</span><span class="p">)))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mean_off_policy_est</span><span class="p">)</span> <span class="o">+</span> <span class="n">penalty</span>
        
        <span class="k">return</span> <span class="n">loss</span>

   
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">        epochs : int, default </span>
<span class="sd">            Number of training epochs.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="n">train_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
        
        
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
       
        <span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">Model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">=</span> <span class="n">n_actions</span><span class="p">)</span>
        
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">Model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>  
       
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">train_epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
                <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">train_epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">: | Train Poem Loss: </span><span class="si">{</span><span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            
        <span class="n">Model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">est_best_policy</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
         
        <span class="k">return</span> <span class="bp">self</span>
    
    

<span class="k">class</span> <span class="nc">CounterfactualRiskMinimizationCV</span><span class="p">(</span><span class="n">CounterfactualRiskMinimization</span><span class="p">,</span> <span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tune variance penalty for Counterfactual Risk Minimization.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    batch_size : int, default: 96</span>
<span class="sd">        The number of samples per batch to load </span>
<span class="sd">    learning_rate : float, default: 0.01</span>
<span class="sd">        Stochastic gradient descent learning rate </span>
<span class="sd">    weight_decay : float, default: 0.001</span>
<span class="sd">        L2 regularization on parameters</span>
<span class="sd">    self_normalize: bool, default: True</span>
<span class="sd">        Whether to normalize the IPS estimator. See [2].</span>
<span class="sd">    clipping: float, default: 100.</span>
<span class="sd">        Clipping the importance sample weights. See [1].</span>
<span class="sd">    verbose: bool, default: True</span>
<span class="sd">        Whether to print Poem Loss during training .</span>
<span class="sd">    lambda_ : 1D array, optional, defaults to grid of values </span>
<span class="sd">        chosen in a logarithmic scale between 1e-4 and 1e+01.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">96</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> 
                 <span class="n">self_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">clipping</span> <span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                 <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span> <span class="o">=</span> <span class="n">self_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="n">clipping</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        
        <span class="k">if</span> <span class="n">lambda_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># search in log scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">=</span> <span class="n">lambda_</span>
                           
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_get_params_min_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">xmin_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">l_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">[</span><span class="n">xmin_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
          
        <span class="k">return</span> <span class="n">l_best</span>

    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">valid_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">        valid_frac : float, default: 0.5</span>
<span class="sd">            Fraction of training data set for validation. Test data are not modified. </span>
<span class="sd">        epochs : int, default: 500</span>
<span class="sd">            Number of training epochs.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_frac</span> <span class="o">=</span> <span class="n">valid_frac</span>
        
        <span class="n">n_train_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">idx_valid_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">),</span> 
                                              <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n_train_samples</span> <span class="o">*</span> <span class="n">valid_frac</span><span class="p">)),</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        
        <span class="n">train_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
        
        
        <span class="n">valid_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
            
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">y_valid</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
       
        <span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">Model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="o">=</span><span class="n">n_actions</span><span class="p">)</span>
        
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">Model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>  
           
        <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span>   
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
    
        <span class="k">for</span> <span class="n">l_idx</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">):</span>
       
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
                <span class="n">train_epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
                <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
                    <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">train_epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> | Train Poem Loss: </span><span class="si">{</span><span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
                <span class="n">Model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">valid_tot_loss</span><span class="o">=</span><span class="mf">0.</span>
                    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">:</span>
                        <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                        <span class="n">valid_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
                        <span class="n">valid_tot_loss</span> <span class="o">+=</span> <span class="n">valid_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">valid_tot_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                      <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                          <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> | Valid Poem Loss: </span><span class="si">{</span><span class="n">valid_tot_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
                <span class="n">pred_train</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">est_best_policy_train</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_train</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_train</span> <span class="o">=</span> <span class="n">est_best_policy_train</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">pred_valid</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">est_best_policy_valid</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_valid</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_valid</span> <span class="o">=</span> <span class="n">est_best_policy_valid</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
                
                <span class="n">pred_test</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
                <span class="n">est_best_policy_test</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_test</span> <span class="o">=</span> <span class="n">est_best_policy_test</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span>
            
                          
        <span class="bp">self</span><span class="o">.</span><span class="n">l_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_params_min_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="p">)</span>
            
    
        
        <span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">lambda_</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l_best</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                              <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
                                              <span class="n">clipping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="n">self_normalize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
         
        <span class="n">crm</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span>
                
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">plot_cv_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
         
        <span class="n">train_loss_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">valid_loss_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">train_acc_flatten</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">valid_acc_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">test_acc_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">fs</span> <span class="o">=</span> <span class="mi">8</span>
        
        <span class="k">for</span> <span class="n">l_idx</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">):</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_loss_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train: Poem Loss&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Validation: Poem Loss&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Validation: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Test: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="alternative-using-doubly-robust-as-opposed-to-the-ips-estimator">
<h2>Alternative using Doubly Robust (as opposed to the IPS estimator)<a class="headerlink" href="#alternative-using-doubly-robust-as-opposed-to-the-ips-estimator" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># class CounterfactualRiskMinimization(EvaluationMetrics):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Performs policy learning using the Counterfactual Risk Minimization </span>
<span class="c1">#     approach proposed in [1], and later refined in [2].</span>
    
<span class="c1">#     Parameters</span>
<span class="c1">#     ----------</span>
<span class="c1">#     batch_size : int, default: 96</span>
<span class="c1">#         The number of samples per batch to load </span>
<span class="c1">#     learning_rate : float, default: 0.01</span>
<span class="c1">#         Stochastic gradient descent learning rate </span>
<span class="c1">#     weight_decay : float, default: 0.001</span>
<span class="c1">#         L2 regularization on parameters</span>
<span class="c1">#     lambda_ : float, default: 0.1</span>
<span class="c1">#         Variance regularization. Penalty on the variance of the </span>
<span class="c1">#         learnt policy relative to the logging policy.</span>
<span class="c1">#     self_normalize: bool, default: True</span>
<span class="c1">#         Whether to normalize the IPS estimator. See [2].</span>
<span class="c1">#     clipping: float, default: 100.</span>
<span class="c1">#         Clipping the importance sample weights. See [1].</span>
<span class="c1">#     verbose: bool, default: False</span>
<span class="c1">#         Whether to print Poem Loss during training .</span>
    
<span class="c1">#     References</span>
<span class="c1">#     ----------</span>
    
<span class="c1">#     .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="c1">#            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="c1">#            1731--1755, 2015.</span>
<span class="c1">#     .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="c1">#            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="c1">#     .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="c1">#            International Conference on Learning Representations,  2018.</span>
    
<span class="c1">#     &quot;&quot;&quot;</span>

    
<span class="c1">#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, </span>
<span class="c1">#                  lambda_: float = 0.5, self_normalize: bool = True, clipping : float = 100.,</span>
<span class="c1">#                  verbose: bool = False) -&gt; None:</span>
<span class="c1">#         self.batch_size = batch_size</span>
<span class="c1">#         self.learning_rate = learning_rate</span>
<span class="c1">#         self.weight_decay = weight_decay</span>
<span class="c1">#         self.lambda_ = lambda_</span>
<span class="c1">#         self.self_normalize = self_normalize</span>
<span class="c1">#         self.verbose = verbose</span>
<span class="c1">#         self.clipping = clipping </span>
     
<span class="c1">#     def __repr__(self) -&gt; str:</span>
    
<span class="c1">#         items = (&quot;%s = %r&quot; % (k, v) for k, v in self.__dict__.items())</span>
<span class="c1">#         return &quot;&lt;%s: {%s}&gt;&quot; % (self.__class__.__name__, &#39;, &#39;.join(items))</span>
  
<span class="c1">#     def _poem_loss(self, pi, p0, r, r_pred, y_idx, Lambda, self_normalize):</span>
        
<span class="c1">#         #if torch.sum(r) == 0: </span>
<span class="c1">#         #    r = torch.repeat_interleave(torch.tensor(1e-05, dtype=torch.float), len(r))</span>
        
        
<span class="c1">#         bsz = pi.shape[0]</span>
<span class="c1">#         softmax_pi = F.softmax(pi, dim=1)</span>
<span class="c1">#         pi_i = softmax_pi.masked_select(y_idx)</span>
<span class="c1">#         r_pred_i = r_pred.masked_select(y_idx)</span>
<span class="c1">#         importance = torch.div(pi_i, p0) </span>
<span class="c1">#         clip_importance_vals = torch.repeat_interleave(torch.tensor(self.clipping, dtype=torch.float), len(importance))</span>
<span class="c1">#         importance_clipped = torch.min(clip_importance_vals, importance)</span>
<span class="c1">#         reward_residual = torch.sub(r, r_pred_i)</span>
<span class="c1">#         weighted_reward_pred = torch.sum(torch.mul(softmax_pi, r_pred), dim=1)</span>
<span class="c1">#         off_policy_est = torch.add(torch.mul(importance_clipped, reward_residual), weighted_reward_pred)</span>
<span class="c1">#         empirical_var = torch.var(off_policy_est)</span>
        
<span class="c1">#         if self_normalize:</span>
<span class="c1">#             effective_sample_size = torch.sum(importance_clipped).detach() # turns off requires grad</span>
<span class="c1">#             sum_off_policy_est = torch.div(torch.sum(off_policy_est), effective_sample_size) </span>
<span class="c1">#         else:</span>
<span class="c1">#             sum_off_policy_est = torch.sum(off_policy_est)</span>
        
<span class="c1">#         penalty = torch.mul(Lambda, torch.sqrt(torch.div(empirical_var, bsz)))</span>
<span class="c1">#         loss = torch.mul(-1.0, sum_off_policy_est) + penalty</span>
             
<span class="c1">#         return loss</span>

    
<span class="c1">#     def learn_policy(self, model, data, epochs: int = 500) -&gt; None:</span>

<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         data : STBT object</span>
<span class="c1">#             This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="c1">#             `generate_batch` method.</span>
<span class="c1">#         epochs : int, default </span>
<span class="c1">#             Number of training epochs.</span>
            
<span class="c1">#         Returns</span>
<span class="c1">#         -------</span>
<span class="c1">#         int.</span>
<span class="c1">#           The predicted best policy.</span>
        
<span class="c1">#         &quot;&quot;&quot; </span>
        
<span class="c1">#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)</span>
        
<span class="c1">#         train_ds = BanditDataset(torch.from_numpy(data.X_train).float(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging).long(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_prob).float(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_reward).long(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging_idx).bool(),</span>
<span class="c1">#                                  torch.from_numpy(rp.train_pred_reward_arr).float() </span>
<span class="c1">#                                  )</span>
        
        
<span class="c1">#         n_features = train_ds.X.shape[1]</span>
<span class="c1">#         actions = torch.unique(train_ds.y)</span>
<span class="c1">#         n_actions = len(actions)</span>
       
<span class="c1">#         train_dl = DataLoader(train_ds, self.batch_size)</span>
        
<span class="c1">#         Model = model(n_features = n_features, n_actions = n_actions)</span>
        
<span class="c1">#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  </span>
        
<span class="c1">#         for epoch in range(epochs):</span>
<span class="c1">#             Model.train()</span>
<span class="c1">#             train_epoch_loss = 0.</span>
<span class="c1">#             for x_batch, y_batch, p0_batch, r_batch, y_idx_batch, r_pred_batch in train_dl:</span>
<span class="c1">#                 pi = Model(x_batch)</span>
<span class="c1">#                 loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, self.lambda_, self.self_normalize)</span>
<span class="c1">#                 loss.backward()</span>
<span class="c1">#                 optimizer.step()</span>
<span class="c1">#                 optimizer.zero_grad()</span>
<span class="c1">#                 train_epoch_loss += loss.item()</span>
<span class="c1">#             if self.verbose:</span>
<span class="c1">#                 print(f&#39;Epoch {epoch}: | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}&#39;)</span>
            
<span class="c1">#         Model.eval()</span>
<span class="c1">#         with torch.no_grad():</span>
<span class="c1">#            X_test = torch.from_numpy(data.X_test).float()</span>
<span class="c1">#            pred = Model(X_test)</span>
<span class="c1">#            est_best_policy = actions[torch.argmax(pred, dim=1)]</span>
            
<span class="c1">#         self.est_best_policy = est_best_policy.numpy()</span>
         
<span class="c1">#         return self</span>
    
    

<span class="c1"># class CounterfactualRiskMinimizationCV(CounterfactualRiskMinimization, EvaluationMetrics):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Tune variance regularizer for Counterfactual Risk Minimization.</span>
    
<span class="c1">#     Parameters</span>
<span class="c1">#     ----------</span>
    
<span class="c1">#     batch_size : int, default: 96</span>
<span class="c1">#         The number of samples per batch to load </span>
<span class="c1">#     learning_rate : float, default: 0.01</span>
<span class="c1">#         Stochastic gradient descent learning rate </span>
<span class="c1">#     weight_decay : float, default: 0.001</span>
<span class="c1">#         L2 regularization on parameters</span>
<span class="c1">#     clipping: float, default: 100.</span>
<span class="c1">#         Clipping the importance sample weights. See [1].</span>
<span class="c1">#     self_normalize: bool, default: True</span>
<span class="c1">#         Whether to normalize the IPS estimator. See [2].</span>
<span class="c1">#     verbose: bool, default: True</span>
<span class="c1">#         Whether to print Poem Loss during training .</span>
<span class="c1">#     lambda_ : 1D array, optional, defaults to grid of values </span>
<span class="c1">#         chosen in a logarithmic scale between 1e-4 and 1e+01.</span>
    
<span class="c1">#     &quot;&quot;&quot;</span>
    
<span class="c1">#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, </span>
<span class="c1">#                  clipping : float = 100., self_normalize: bool = True, verbose: bool = False, </span>
<span class="c1">#                  lambda_: np.ndarray = None) -&gt; None:</span>
        
<span class="c1">#         self.batch_size = batch_size</span>
<span class="c1">#         self.learning_rate = learning_rate</span>
<span class="c1">#         self.weight_decay = weight_decay</span>
<span class="c1">#         self.clipping = clipping </span>
<span class="c1">#         self.self_normalize = self_normalize</span>
<span class="c1">#         self.verbose = verbose</span>
        
<span class="c1">#         if lambda_ is None:</span>
<span class="c1">#             self.lambda_ = 10 ** np.linspace(-4., 1., 10) # search in log scale</span>
<span class="c1">#         else:</span>
<span class="c1">#             self.lambda_= lambda_</span>
                           
<span class="c1">#     def __repr__(self) -&gt; str:</span>
    
<span class="c1">#         items = (&quot;%s = %r&quot; % (k, v) for k, v in self.__dict__.items())</span>
<span class="c1">#         return &quot;&lt;%s: {%s}&gt;&quot; % (self.__class__.__name__, &#39;, &#39;.join(items))</span>
    
<span class="c1">#     def _get_params_min_loss(self, x):</span>
<span class="c1">#         x = x.numpy()</span>
<span class="c1">#         xmin_idx = np.unravel_index(x.argmin(), x.shape)</span>
<span class="c1">#         l_best = self.lambda_[xmin_idx[0]]</span>
          
<span class="c1">#         return l_best</span>

    
<span class="c1">#     def learn_policy(self, model, data, valid_frac: float = 0.5, epochs: int = 500) -&gt; None:</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         data : STBT object</span>
<span class="c1">#             This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="c1">#             `generate_batch` method.</span>
<span class="c1">#         valid_frac : float, default: 0.5</span>
<span class="c1">#             Fraction of training data set for validation. Test data are not modified. </span>
<span class="c1">#         epochs : int, default: 500</span>
<span class="c1">#             Number of training epochs.</span>
            
<span class="c1">#         Returns</span>
<span class="c1">#         -------</span>
<span class="c1">#         int.</span>
<span class="c1">#           The predicted best policy.</span>
        
<span class="c1">#         &quot;&quot;&quot; </span>
        
<span class="c1">#         self.epochs = epochs</span>
<span class="c1">#         self.valid_frac = valid_frac</span>
        
<span class="c1">#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)</span>
        
<span class="c1">#         n_train_samples, n_features = data.X_train.shape</span>
<span class="c1">#         idx_valid_samples = np.random.choice(range(n_train_samples), </span>
<span class="c1">#                                              size = int(np.floor(n_train_samples * valid_frac)), replace = False)</span>
        
<span class="c1">#         train_ds = BanditDataset(torch.from_numpy(np.delete(data.X_train, idx_valid_samples, axis=0)).float(),</span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.y_train_logging, idx_valid_samples)).long(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.train_logging_prob, idx_valid_samples)).float(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.train_logging_reward, idx_valid_samples)).long(),</span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.y_train_logging_idx, idx_valid_samples, axis=0)).bool(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(rp.train_pred_reward_arr, idx_valid_samples, axis=0)).float()</span>
<span class="c1">#                                  )</span>
        
        
<span class="c1">#         valid_ds = BanditDataset(torch.from_numpy(data.X_train[idx_valid_samples, :]).float(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging[idx_valid_samples]).long(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_prob[idx_valid_samples]).float(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_reward[idx_valid_samples]).long(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging_idx[idx_valid_samples, :]).bool(),</span>
<span class="c1">#                                  torch.from_numpy(rp.train_pred_reward_arr[idx_valid_samples, :]).float()</span>
<span class="c1">#                                  )</span>
            
<span class="c1">#         y_train = np.delete(data.y_train, idx_valid_samples, axis=0)</span>
<span class="c1">#         y_valid = data.y_train[idx_valid_samples]</span>
<span class="c1">#         X_test = torch.from_numpy(data.X_test).float()</span>
        
<span class="c1">#         actions = torch.unique(train_ds.y)</span>
<span class="c1">#         n_actions = len(actions)</span>
       
<span class="c1">#         train_dl = DataLoader(train_ds, self.batch_size)</span>
<span class="c1">#         valid_dl = DataLoader(valid_ds, self.batch_size)</span>
        
<span class="c1">#         Model = model(n_features=n_features, n_actions=n_actions)</span>
        
<span class="c1">#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  </span>
           
<span class="c1">#         self.train_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)   </span>
<span class="c1">#         self.valid_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)</span>
<span class="c1">#         self.valid_acc = torch.zeros(len(self.lambda_), epochs) </span>
<span class="c1">#         self.train_acc = torch.zeros(len(self.lambda_), epochs) </span>
<span class="c1">#         self.test_acc = torch.zeros(len(self.lambda_), epochs) </span>
    
<span class="c1">#         for l_idx, l in enumerate(self.lambda_):</span>
       
<span class="c1">#             for epoch in range(epochs):</span>
<span class="c1">#                 Model.train()</span>
<span class="c1">#                 train_epoch_loss = 0.</span>
<span class="c1">#                 for x_batch, y_batch, p0_batch,r_batch,y_idx_batch,r_pred_batch in train_dl:</span>
<span class="c1">#                     pi = Model(x_batch)</span>
<span class="c1">#                     loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)</span>
<span class="c1">#                     loss.backward()</span>
<span class="c1">#                     optimizer.step()</span>
<span class="c1">#                     optimizer.zero_grad()</span>
<span class="c1">#                     train_epoch_loss += loss.item()</span>
<span class="c1">#                 self.train_tot_loss_hist[l_idx, epoch] = train_epoch_loss/len(train_dl)</span>
<span class="c1">#                 if self.verbose:</span>
<span class="c1">#                     print(f&#39;Epoch: {epoch} | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}&#39;)</span>
                
<span class="c1">#                 Model.eval()</span>
<span class="c1">#                 with torch.no_grad():</span>
<span class="c1">#                     valid_tot_loss=0.</span>
<span class="c1">#                     for x_batch,y_batch,p0_batch,r_batch,y_idx_batch,r_pred_batch in valid_dl:</span>
<span class="c1">#                         pi = Model(x_batch)</span>
<span class="c1">#                         valid_loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)</span>
<span class="c1">#                         valid_tot_loss += valid_loss.item()</span>
<span class="c1">#                 self.valid_tot_loss_hist[l_idx, epoch] = valid_tot_loss/len(valid_dl)</span>
<span class="c1">#                 if self.verbose:</span>
<span class="c1">#                       print(f&#39;Epoch: {epoch} | Valid Poem Loss: {valid_tot_loss/len(valid_dl):.5f}&#39;)</span>
                
<span class="c1">#                 pred_train = Model(train_ds.X)</span>
<span class="c1">#                 est_best_policy_train = actions[torch.argmax(pred_train, dim=1)]</span>
<span class="c1">#                 est_best_policy_train = est_best_policy_train.numpy()</span>
<span class="c1">#                 self.train_acc[l_idx, epoch] = self.error_rate(est_best_policy_train, y_train)</span>
<span class="c1">#                 pred_valid = Model(valid_ds.X)</span>
<span class="c1">#                 est_best_policy_valid = actions[torch.argmax(pred_valid, dim=1)]</span>
<span class="c1">#                 est_best_policy_valid = est_best_policy_valid.numpy()</span>
<span class="c1">#                 self.valid_acc[l_idx, epoch] = self.error_rate(est_best_policy_valid, y_valid)</span>
                
<span class="c1">#                 pred_test = Model(X_test)</span>
<span class="c1">#                 est_best_policy_test = actions[torch.argmax(pred_test, dim=1)]</span>
<span class="c1">#                 est_best_policy_test = est_best_policy_test.numpy()</span>
<span class="c1">#                 self.test_acc[l_idx, epoch] = self.error_rate(est_best_policy_test, data.y_test)</span>
            
                          
<span class="c1">#         self.l_best = self._get_params_min_loss(self.valid_tot_loss_hist)</span>
            
    
        
<span class="c1">#         crm = CounterfactualRiskMinimization(lambda_=self.l_best, batch_size = self.batch_size,</span>
<span class="c1">#                                              learning_rate = self.learning_rate, weight_decay = self.weight_decay,</span>
<span class="c1">#                                              clipping = self.clipping, self_normalize = self.self_normalize, verbose = self.verbose)</span>
        
<span class="c1">#         crm.learn_policy(model=model, data=data, epochs=epochs) </span>
<span class="c1">#         self.est_best_policy = crm.est_best_policy</span>
                
<span class="c1">#         return self</span>
    
<span class="c1">#     def plot_cv_loss(self):</span>
         
<span class="c1">#         train_loss_flatten = self.train_tot_loss_hist.T.flatten(1).numpy()</span>
<span class="c1">#         valid_loss_flatten = self.valid_tot_loss_hist.T.flatten(1).numpy()</span>
        
<span class="c1">#         train_acc_flatten =  self.train_acc.T.flatten(1).numpy()</span>
<span class="c1">#         valid_acc_flatten = self.valid_acc.T.flatten(1).numpy()</span>
<span class="c1">#         test_acc_flatten = self.test_acc.T.flatten(1).numpy()</span>
        
<span class="c1">#         fig, axs = plt.subplots(2, 3)</span>
<span class="c1">#         fs = 8</span>
        
<span class="c1">#         for l_idx, l in enumerate(self.lambda_):</span>
<span class="c1">#             axs[0, 0].plot(train_loss_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[0, 1].plot(valid_loss_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 0].plot(train_acc_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 1].plot(valid_acc_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 2].plot(test_acc_flatten[:,l_idx], label = round(l, 4))</span>
            
<span class="c1">#         axs[0, 0].set_title(&quot;Train: Poem Loss&quot;, fontsize=fs)</span>
<span class="c1">#         axs[0, 1].set_title(&quot;Validation: Poem Loss&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 0].set_title(&quot;Train: Accuracy&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 1].set_title(&quot;Validation: Accuracy&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 2].set_title(&quot;Test: Accuracy&quot;, fontsize=fs)</span>
        
<span class="c1">#         for i, ax in enumerate(axs.flat):</span>
<span class="c1">#             if i &lt; 2:</span>
<span class="c1">#                 ax.set_xlabel(xlabel=&#39;Epoch&#39;, fontsize=fs)</span>
<span class="c1">#                 ax.set_ylabel(ylabel=&#39;Loss&#39;, fontsize=fs)</span>
<span class="c1">#             else:</span>
<span class="c1">#                 ax.set_xlabel(xlabel=&#39;Epoch&#39;, fontsize=fs)</span>
<span class="c1">#                 ax.set_ylabel(ylabel=&#39;Accuracy&#39;, fontsize=fs)</span>
<span class="c1">#         fig.legend(self.lambda_, loc=&#39;upper right&#39;, fontsize=fs)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="read-data">
<h2>Read data<a class="headerlink" href="#read-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="s1">&#39;glass&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="perform-supervised-to-bandit-conversion">
<h2>Perform Supervised-to-Bandit Conversion<a class="headerlink" href="#perform-supervised-to-bandit-conversion" title="Permalink to this headline">¶</a></h2>
<p>Performs Supervised to Bandit Conversion for classification datasets. This conversion is generally used to test the limits of counterfactual learning in a well-controlled environment.</p>
<p>Here, we take a supervised dataset with features x and labeled classes y, and simulate a bandit feedback data set from a logging policy. Basically, this involves: (i) simulating a stochastic logging policy, which may be uniform (logging_type=’uniform’), or given as a function of covariates (logging_type = ‘biased’), (ii) when the logging policy for a given observation equals the optimal policy (true label), a positive reward is observed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">(</span><span class="n">train_frac</span><span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">logging_type</span><span class="o">=</span><span class="s1">&#39;biased&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="skyline">
<h2>Skyline<a class="headerlink" href="#skyline" title="Permalink to this headline">¶</a></h2>
<p>Best possible error rate, assuming we have full feedback (this can only be tested from the simulation as in practice as we have bandit feedback)x.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">optimal_policy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Skyline Error:&quot;</span><span class="p">,</span> <span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">optimal_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skyline Error: 0.30841121495327106
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Reward Predictor (RP)</span>
<span class="n">rp</span> <span class="o">=</span> <span class="n">RewardPredictor</span><span class="p">()</span>
<span class="n">rp</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reward Predictor Error:&quot;</span><span class="p">,</span> <span class="n">rp</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reward Predictor Error: 0.7009345794392523
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Outcome Weighted Learning (OWL)</span>
<span class="n">owl</span> <span class="o">=</span> <span class="n">OutcomeWeightedLearning</span><span class="p">()</span>
<span class="n">owl</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">clf</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;OWL-LR:&quot;</span><span class="p">,</span> <span class="n">owl</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">owl</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OWL-LR: 0.7289719626168225
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="counterfactual-risk-minimization-crm">
<h2>Counterfactual Risk Minimization (CRM)<a class="headerlink" href="#counterfactual-risk-minimization-crm" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="mf">1e-06</span><span class="p">)</span>
<span class="n">crm</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">LinearModel</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CRM:&quot;</span><span class="p">,</span> <span class="n">crm</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0: | Train Poem Loss: -0.10087
Epoch 100: | Train Poem Loss: -0.23397
Epoch 200: | Train Poem Loss: -0.37680
Epoch 300: | Train Poem Loss: -0.49386
Epoch 400: | Train Poem Loss: -0.54733
Epoch 500: | Train Poem Loss: -0.57395
Epoch 600: | Train Poem Loss: -0.58959
Epoch 700: | Train Poem Loss: -0.60032
Epoch 800: | Train Poem Loss: -0.60866
Epoch 900: | Train Poem Loss: -0.61578
Epoch 1000: | Train Poem Loss: -0.62223
Epoch 1100: | Train Poem Loss: -0.62831
Epoch 1200: | Train Poem Loss: -0.63413
Epoch 1300: | Train Poem Loss: -0.63967
Epoch 1400: | Train Poem Loss: -0.64488
Epoch 1500: | Train Poem Loss: -0.64968
Epoch 1600: | Train Poem Loss: -0.65401
Epoch 1700: | Train Poem Loss: -0.65786
Epoch 1800: | Train Poem Loss: -0.66122
Epoch 1900: | Train Poem Loss: -0.66412
CRM: 0.719626168224299
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="experiments">
<h2>Experiments<a class="headerlink" href="#experiments" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Params</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Number of simulations</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">LOGGING_TYPE</span> <span class="o">=</span> <span class="s1">&#39;biased&#39;</span>
<span class="n">MODEL</span> <span class="o">=</span> <span class="n">LinearModel</span>
<span class="n">LAMBDA</span> <span class="o">=</span> <span class="mf">1e-06</span>
<span class="n">DATASETS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">]</span>
<span class="n">dat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">skyline_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">randomized_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">reward_predictor_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">owl_lrcv_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">crm_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">DATASETS</span><span class="p">:</span>
    
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample: </span><span class="si">%d</span><span class="s2"> - Dataset: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
        
        <span class="n">d</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">(</span><span class="n">logging_type</span> <span class="o">=</span> <span class="n">LOGGING_TYPE</span><span class="p">)</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">dat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>    
       
        <span class="n">skyline</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">optimal_policy</span> <span class="o">=</span> <span class="n">skyline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
        
        <span class="n">rp</span> <span class="o">=</span> <span class="n">RewardPredictor</span><span class="p">()</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">erm_lrcv</span> <span class="o">=</span> <span class="n">OutcomeWeightedLearning</span><span class="p">()</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">clf</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">lambda_</span><span class="o">=</span><span class="n">LAMBDA</span><span class="p">)</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>     
        
        <span class="n">skyline_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">optimal_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">randomized_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">reward_predictor_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">owl_lrcv_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">erm_lrcv</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">erm_lrcv</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">crm_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: ecoli
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  % (min_groups, self.n_splits)), UserWarning)
/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  % (min_groups, self.n_splits)), UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: glass
Sample: 0 - Dataset: lymphography
Sample: 0 - Dataset: yeast
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: digits
Sample: 0 - Dataset: breast-cancer
Sample: 0 - Dataset: wine
Sample: 0 - Dataset: letter-recognition
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;dataset&#39;</span><span class="p">:</span><span class="n">dat</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="s1">&#39;skyline_error&#39;</span><span class="p">:</span> <span class="n">skyline_error</span><span class="p">,</span> <span class="s1">&#39;randomized_error&#39;</span><span class="p">:</span><span class="n">randomized_error</span><span class="p">,</span> <span class="s1">&#39;reward_predictor_error&#39;</span><span class="p">:</span><span class="n">reward_predictor_error</span><span class="p">,</span>
                              <span class="s1">&#39;owl_lrcv_error&#39;</span><span class="p">:</span><span class="n">owl_lrcv_error</span><span class="p">,</span> <span class="s1">&#39;crm_error&#39;</span><span class="p">:</span><span class="n">crm_error</span><span class="p">})</span>

<span class="n">res_summary</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span>
                            <span class="s1">&#39;skyline_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;randomized_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;reward_predictor_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;owl_lrcv_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;crm_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
                            <span class="p">})</span>

<span class="n">res_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>dataset</th>
      <th colspan="2" halign="left">skyline_error</th>
      <th colspan="2" halign="left">randomized_error</th>
      <th colspan="2" halign="left">reward_predictor_error</th>
      <th colspan="2" halign="left">owl_lrcv_error</th>
      <th colspan="2" halign="left">crm_error</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>breast-cancer</td>
      <td>0.029123</td>
      <td>0.009792</td>
      <td>0.558596</td>
      <td>0.191854</td>
      <td>0.026667</td>
      <td>0.009813</td>
      <td>0.209825</td>
      <td>0.162483</td>
      <td>0.064561</td>
      <td>0.051467</td>
    </tr>
    <tr>
      <th>1</th>
      <td>digits</td>
      <td>0.036151</td>
      <td>0.004104</td>
      <td>0.888432</td>
      <td>0.054886</td>
      <td>0.376529</td>
      <td>0.096568</td>
      <td>0.529366</td>
      <td>0.120459</td>
      <td>0.426251</td>
      <td>0.111795</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ecoli</td>
      <td>0.132937</td>
      <td>0.018231</td>
      <td>0.835714</td>
      <td>0.093679</td>
      <td>0.278175</td>
      <td>0.043127</td>
      <td>0.397619</td>
      <td>0.178276</td>
      <td>0.310714</td>
      <td>0.080024</td>
    </tr>
    <tr>
      <th>3</th>
      <td>glass</td>
      <td>0.401869</td>
      <td>0.037642</td>
      <td>0.825234</td>
      <td>0.061372</td>
      <td>0.588785</td>
      <td>0.103134</td>
      <td>0.591589</td>
      <td>0.080883</td>
      <td>0.629907</td>
      <td>0.093996</td>
    </tr>
    <tr>
      <th>4</th>
      <td>letter-recognition</td>
      <td>0.228200</td>
      <td>0.004190</td>
      <td>0.966280</td>
      <td>0.011429</td>
      <td>0.737560</td>
      <td>0.031631</td>
      <td>0.713590</td>
      <td>0.030353</td>
      <td>0.741250</td>
      <td>0.028611</td>
    </tr>
    <tr>
      <th>5</th>
      <td>lymphography</td>
      <td>0.168919</td>
      <td>0.032638</td>
      <td>0.748649</td>
      <td>0.075965</td>
      <td>0.295946</td>
      <td>0.067553</td>
      <td>0.347297</td>
      <td>0.111444</td>
      <td>0.410811</td>
      <td>0.119722</td>
    </tr>
    <tr>
      <th>6</th>
      <td>wine</td>
      <td>0.026966</td>
      <td>0.022596</td>
      <td>0.723596</td>
      <td>0.098695</td>
      <td>0.065169</td>
      <td>0.047611</td>
      <td>0.365169</td>
      <td>0.104097</td>
      <td>0.158427</td>
      <td>0.094074</td>
    </tr>
    <tr>
      <th>7</th>
      <td>yeast</td>
      <td>0.411456</td>
      <td>0.011078</td>
      <td>0.901482</td>
      <td>0.024659</td>
      <td>0.516981</td>
      <td>0.058388</td>
      <td>0.606334</td>
      <td>0.062139</td>
      <td>0.569946</td>
      <td>0.045408</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52), 1731–1755, 2015.</p>
<p>[2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, Advances in Neural Information Processing Systems, 28, 16(52), 3231–3239, 2015.</p>
<p>[3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, International Conference on Learning Representations, 2018.</p>
<p>[4] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, 107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.</p>
<p>[5] Y. Wang, A. Agarwal and M. Dud’{\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, Proceedings of Machine Learning Research, 70, 3589–3597, 2017.</p>
<p>[6] M. Dudik and J. Langford and L. Li, Doubly Robust Policy Evaluation and Learning, CoRR, 2011. <a class="reference external" href="http://arxiv.org/abs/1103.4601">http://arxiv.org/abs/1103.4601</a></p>
<p>[7] K{“u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous treatment effects using machine learning, Proceedings of the National Academy of Sciences, 116(10), 4156–4165, 2019.</p>
<p>[8] Batch Learning from Bandit Feedback (BLBF). <a class="reference external" href="https://github.com/leoguelman/BLBF">https://github.com/leoguelman/BLBF</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/ope-rec",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="sidebar bd-sidebar inactive" id="site-navigation">

                <div class="sidebar__header">


                    Contents

                </div>

                <nav class="sidebar__nav" id="sidebar-nav" aria-label="Main navigation">
                    <ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="US773842_Off_Policy_Evaluation.html">
   Off-Policy Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="L978189_Counterfactual_Policy_Evaluation.html">
   Counterfactual policy evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L845850_Evaluating_non_stationary_policies.html">
   Evaluating non-stationary policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L036590_Online_vs_Offline_Evaluation.html">
   Online vs Offline Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datasets
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="L410896_Open_Bandit_Dataset.html">
   Open Bandit Dataset
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="L910228_OBP_Library.html">
   OBP Library
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="C862189_Direct_method.html">
   Direct method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C674274_Inverse_Propensity_Weighting.html">
   Inverse Propensity Weighting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C235655_Doubly_Robust.html">
   Doubly Robust
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="T167249_Offline_Policy_Evaluation_with_VW_Command_Line.html">
   Offline Policy Evaluation with VW Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T966055_OBP_Library_Workshop_Tutorials.html">
   OBP Library Workshop Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T601959_Evaluating_a_New_Fraud_Policy_with_DM%2C_IPW%2C_and_DR_Methods.html">
   Evaluating a New Fraud Policy with DM, IPW, and DR Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T874693_Evaluating_Standard_Off_Policy_Estimators_with_Small_Sample_Open_Bandit_Dataset.html">
   Evaluating Standard Off-Policy Estimators with Small Sample Open-Bandit Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T705904_Evaluation_of_Multiple_Off_Policy_Estimators_on_Synthetic_Dataset.html">
   Evaluation of Multiple Off-Policy Estimators on Synthetic Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html">
   Off-Policy Learning in Two-stage Recommender Systems
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   Batch Learning from Bandit Feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html">
   Evaluating the Robustness of Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T471827_Adaptive_Estimator_Selection_for_Off_Policy_Evaluation.html">
   Adaptive Estimator Selection for Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T792262_Optimal_Off_Policy_Evaluation_from_Multiple_Logging_Policies.html">
   Optimal Off-Policy Evaluation from Multiple Logging Policies
  </a>
 </li>
</ul>

                </nav>

                <div class="sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="toolbar">

            <div class="toolbar__inner">

                <ul class="toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="US773842_Off_Policy_Evaluation.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="" title=""><span class="show-for-sr"></span></a></li>
                    <!-- <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off">
                            <i data-feather="search"></i>
                        </form>
                    </li> -->
                </ul>

                <ul class="toolbar__links">
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                        <li data-tippy-content="Download PDF" onClick="window.print()"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/sparsh-ai/ope-rec/tree/main/docs/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF).ipynb" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="" data-urlpath="" data-branch=>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)";
                const repoURL = "";
                const urlPath = "";
                const branch = ""
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
    
  </body>
</html>